Dataset

src/datagen/extract_protein_features.py reproduces P2Rank-style vectors; the merged CSV at data/vectorsTrain_all_chainfix.csv adds the missing protein_id/chain_id columns, so downstream tooling should always consume this “chainfix” file instead of the raw output_train/vectorsTrain_all.csv.
generate_complete_h5_files.py:355-373 batches residues per protein; when an exact residue match is missing it averages the whole chain embedding, leaving 1 884 entries (0.04 %) in data/h5/pocknet_with_esm2_3b.h5 with residue_numbers == -1—worth tightening before the fallback silently dilutes signals.
The assembled H5 holds 4 937 088 residues with 35 tabular features and a 2.48 % positive rate; splits are {0: 3 889 240 train, 1: 831 014 val, 2: 216 834 BU48 test}, which matches the intended train/val/BU48 layout and should be documented for future runs.
Because the builder requires chain-level ESM files in data/esm2_3B_chain/ and data/bu48_proteins.txt, keep those directories under version control guidance; a missing embedding currently produces silent mean pooling rather than an explicit error.
Training

The experiment wiring in configs/experiment/fusion_all_train_complete.yaml:12-54 targets the shared-memory H5 datamodule with k-NN enabled; confirm PROJECT_ROOT is exported so Hydra can resolve configs/paths/default.yaml:4-11.
configs/model/esm_tabular.yaml:9 still advertises tabular_dim: 39 while the H5 exposes 35 columns—your overrides in the experiment keep things working, but updating the base config avoids silent shape mismatches when new runs reuse the default.
src/data/shared_memory_datamodule_v2.py:564-606 assumes /dev/shm availability and uses BU48 IDs from data/output_train/test_vectorsTrain_all_names_bu48.txt; make sure the runtime environment mounts tmpfs accordingly or provide POCKNET_SHM_DIR.
Optional k-NN enrichment (configs/data/h5_knn_enabled.yaml:5-8) now relies on src/data/practical_knn_utils; confirm those utilities stay in sync with the H5 neighbor schema before switching enable_knn back on.
Post Processing

Core pieces (post_processing/core.py:20, post_processing/production_pipeline.py:69) bail out when scikit-learn, scipy, or BioPython are absent; the current environment falls back to the naïve stubs, so you never reach the intended p2rank-style clustering.
The “production” loaders degrade to heuristics when real structures or RSA can’t be pulled; with BioPython missing you end up normalizing tabular proxies only (post_processing/production_pipeline.py:454-501, post_processing/production_pipeline.py:615-623), so spatial scores no longer reflect solvent geometry.
When the production processor isn’t fully available, _detect_pockets_fallback in post_processing/enhanced_pipeline.py:1102-1134 just grabs the first min_pocket_size residues and assigns canned scores, which explains the one pocket per protein with identical centers in post_processing_results/protein_1a6u_H/pockets.csv:2.
The exported artifacts show the failure clearly: coordinates and true-pocket locations are all zeros in post_processing_results/protein_1a4j_H/predictions.txt:4 and post_processing_results/protein_1a4j_H/true_pockets.txt:4, so the current “summary” is not trustworthy.
post_processing/enhanced_pipeline.py:397-403 wipes post_processing_results/ on every run, which is dangerous once you start generating believable outputs—switch to per-run subfolders or require explicit confirmation.
test_enhanced_pipeline.py:24-45 merely prints status and can’t catch regressions like the above; meaningful assertions (non-zero coordinates, ≥1 true pocket, etc.) are still missing.
Redundant Files

post_processing/run_complete_pipeline.py:1-120 and post_processing/run_post_processing_pipeline.py hard-code mock coordinates and predate the enhanced pipeline; they now only add noise.
post_processing/run_production_pipeline.py duplicates EnhancedPostProcessor logic with even more placeholders; retire it once the enhanced path is fixed.
post_processing/run_advanced_pipeline.py and post_processing/demo_pipeline.py are legacy experiments that still import unavailable dependencies and should be archived.
post_processing/test_pipeline.py and post_processing/test_pipeline_quick.py rely on missing config scaffolding and don’t assert anything; prune or rewrite them around the real pipeline.
Next Steps

Install the missing scientific stack (scikit-learn, scipy, biopython) and update the post-processing entry points to fail fast when a dependency is absent rather than silently using stubs.
Revisit generate_complete_h5_files.py to tighten residue alignment—emit warnings for mean-pooled residues and ensure the BU48 map is injected into the H5 (so later consumers never need the text file).
Refactor _detect_pockets_fallback to call the production pipeline only after structural data succeeds, and port p2rank’s clustering (radius graph + DBSCAN + rescoring) instead of the current “first five residues” placeholder.
Regenerate post_processing_results/ after the above fixes and add assertions in test_enhanced_pipeline.py that check for non-zero coordinates, sensible pocket counts, and metric ranges.
Trim the legacy scripts listed above, then document the one true CLI (post_processing/run_enhanced_pipeline.py) and its configuration so future runs don’t accidentally pick the obsolete entry points.




graf attention
average
transformer attention weights for esm2

nächsten 3 in transformer für weights -> stacken mit weights + sas
esm + disteneces
pytorch multi head attention.
